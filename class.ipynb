{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "class",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jubeam/my_js_project/blob/master/class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3VpWsY3c36k",
        "colab_type": "code",
        "outputId": "607497b9-0071-466e-d5a4-11d46e91fb39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " #0. 사용할 패키지 불러오기\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 랜덤시드 고정시키기\n",
        "np.random.seed(3)\n",
        "\n",
        "# 1. 데이터 생성하기\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive', force_remount=True)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/gdrive/My Drive/Colab Notebooks/train',\n",
        "        target_size=(70, 70),\n",
        "        batch_size=3,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        '/gdrive/My Drive/Colab Notebooks/test',\n",
        "        target_size=(70, 70),    \n",
        "        batch_size=3,\n",
        "    \n",
        "        class_mode='categorical')\n",
        "\n",
        "# 2. 모델 구성하기\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(70,70,3)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# 3. 모델 학습과정 설정하기\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 4. 모델 학습시키기\n",
        "model.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch=15,\n",
        "        epochs=50,\n",
        "        validation_data=test_generator,\n",
        "        validation_steps=5)\n",
        "\n",
        "# 6. 모델 평가하기\n",
        "print(\"-- Evaluate --\")\n",
        "scores = model.evaluate_generator(test_generator, steps=5)\n",
        "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
        "\n",
        "# 7. 모델 사용하기\n",
        "print(\"-- Predict --\")\n",
        "output = model.predict_generator(test_generator, steps=5)\n",
        "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
        "print(test_generator.class_indices)\n",
        "print(output)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n",
            "Found 70 images belonging to 3 classes.\n",
            "Found 12 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0829 06:31:18.435915 139931002976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0829 06:31:18.483536 139931002976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0829 06:31:18.492021 139931002976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0829 06:31:18.556765 139931002976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0829 06:31:18.600858 139931002976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0829 06:31:18.625585 139931002976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0829 06:31:18.767143 139931002976128 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "W0829 06:31:18.836317 139931002976128 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "15/15 [==============================] - 26s 2s/step - loss: 7.2424 - acc: 0.5111 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 2/50\n",
            "15/15 [==============================] - 15s 986ms/step - loss: 7.8560 - acc: 0.5126 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 3/50\n",
            "15/15 [==============================] - 2s 132ms/step - loss: 8.5963 - acc: 0.4667 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 4/50\n",
            "15/15 [==============================] - 2s 122ms/step - loss: 7.8560 - acc: 0.5126 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 5/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 7.5436 - acc: 0.5320 - val_loss: 7.5218 - val_acc: 0.5333\n",
            "Epoch 6/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 8.5963 - acc: 0.4667 - val_loss: 11.8199 - val_acc: 0.2667\n",
            "Epoch 7/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 6.4660 - acc: 0.5988 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 8/50\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 8.5745 - acc: 0.4680 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 9/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 8.5963 - acc: 0.4667 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 10/50\n",
            "15/15 [==============================] - 2s 122ms/step - loss: 6.7783 - acc: 0.5795 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 11/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 7.8800 - acc: 0.5111 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 12/50\n",
            "15/15 [==============================] - 2s 122ms/step - loss: 8.5745 - acc: 0.4680 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 13/50\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 8.5745 - acc: 0.4680 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 14/50\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 7.1636 - acc: 0.5556 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 15/50\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 6.8252 - acc: 0.5766 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 16/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 9.2929 - acc: 0.4234 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 17/50\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 7.1636 - acc: 0.5556 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 18/50\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 8.5745 - acc: 0.4680 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 19/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 7.8800 - acc: 0.5111 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 20/50\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 8.5745 - acc: 0.4680 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 21/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 7.5436 - acc: 0.5320 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 22/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 8.2381 - acc: 0.4889 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 23/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 8.2152 - acc: 0.4903 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 24/50\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 6.8252 - acc: 0.5766 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 25/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 8.2381 - acc: 0.4889 - val_loss: 7.5218 - val_acc: 0.5333\n",
            "Epoch 26/50\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 7.1376 - acc: 0.5572 - val_loss: 11.8199 - val_acc: 0.2667\n",
            "Epoch 27/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 8.2381 - acc: 0.4889 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 28/50\n",
            "15/15 [==============================] - 2s 121ms/step - loss: 8.2621 - acc: 0.4874 - val_loss: 7.5218 - val_acc: 0.5333\n",
            "Epoch 29/50\n",
            "15/15 [==============================] - 2s 122ms/step - loss: 6.8252 - acc: 0.5766 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 30/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 7.8800 - acc: 0.5111 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 31/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 8.9337 - acc: 0.4457 - val_loss: 7.5218 - val_acc: 0.5333\n",
            "Epoch 32/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 7.4968 - acc: 0.5349 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 33/50\n",
            "15/15 [==============================] - 2s 122ms/step - loss: 7.5218 - acc: 0.5333 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 34/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 8.5745 - acc: 0.4680 - val_loss: 7.5218 - val_acc: 0.5333\n",
            "Epoch 35/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 7.8800 - acc: 0.5111 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 36/50\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 5.7475 - acc: 0.6434 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 37/50\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 9.3397 - acc: 0.4205 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 38/50\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 8.2381 - acc: 0.4889 - val_loss: 7.5218 - val_acc: 0.5333\n",
            "Epoch 39/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 7.5436 - acc: 0.5320 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 40/50\n",
            "15/15 [==============================] - 2s 127ms/step - loss: 7.4968 - acc: 0.5349 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 41/50\n",
            "15/15 [==============================] - 2s 128ms/step - loss: 7.8800 - acc: 0.5111 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 42/50\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 6.8252 - acc: 0.5766 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 43/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 8.9545 - acc: 0.4444 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 44/50\n",
            "15/15 [==============================] - 2s 120ms/step - loss: 7.1844 - acc: 0.5543 - val_loss: 9.6709 - val_acc: 0.4000\n",
            "Epoch 45/50\n",
            "15/15 [==============================] - 2s 125ms/step - loss: 7.5436 - acc: 0.5320 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 46/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 7.8800 - acc: 0.5111 - val_loss: 11.8199 - val_acc: 0.2667\n",
            "Epoch 47/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 8.2152 - acc: 0.4903 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 48/50\n",
            "15/15 [==============================] - 2s 123ms/step - loss: 7.8560 - acc: 0.5126 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "Epoch 49/50\n",
            "15/15 [==============================] - 2s 126ms/step - loss: 8.5963 - acc: 0.4667 - val_loss: 10.7454 - val_acc: 0.3333\n",
            "Epoch 50/50\n",
            "15/15 [==============================] - 2s 124ms/step - loss: 6.1068 - acc: 0.6211 - val_loss: 8.5963 - val_acc: 0.4667\n",
            "-- Evaluate --\n",
            "acc: 33.33%\n",
            "-- Predict --\n",
            "{'cancer': 0, 'etc': 1, 'normal': 2}\n",
            "[[0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]\n",
            " [0.000 0.000 1.000]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrAFZ8Znc6Rw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}