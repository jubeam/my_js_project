{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_실습.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jubeam/my_js_project/blob/master/CNN_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqPacsBowt7A",
        "colab_type": "code",
        "outputId": "f59ce506-bb75-4ed0-fe56-200557d2ab1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve('http://doc.mindscale.kr/km/unstructured/dog-vs-cat.zip',\n",
        "            'dog-vs-cat.zip')\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('dog-vs-cat.zip') as z:\n",
        "    z.extractall()\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_gen = ImageDataGenerator(\n",
        "        rescale=1/255,         # 픽셀 값을 0~1 범위로 변환\n",
        "        rotation_range=40,      # 40도까지 회전\n",
        "        width_shift_range=0.2,  # 20%까지 좌우 이동\n",
        "        height_shift_range=0.2, # 20%까지 상하 이동\n",
        "        shear_range=0.2,        # 20%까지 기울임\n",
        "        zoom_range=0.2,         # 20%까지 확대\n",
        "        horizontal_flip=True,   # 좌우 뒤집기\n",
        "    )\n",
        "\n",
        "train = img_gen.flow_from_directory(\n",
        "    'dog-vs-cat/train',     # 이미지 디렉토리\n",
        "    target_size=(100, 100), # 변환할 크기는 가로 100, 세로 100\n",
        "    color_mode='rgb',       # 컬러는 rgb, 흑백은 grayscale. 생략하면 컬러로 처리한다\n",
        "    class_mode='binary')    # 고양이 vs. 개로 binary 분류\n",
        "\n",
        "valid = ImageDataGenerator(rescale=1/255).flow_from_directory(\n",
        "    'dog-vs-cat/validation',\n",
        "    target_size=(100, 100),\n",
        "    class_mode='binary',\n",
        "    shuffle=False)\n",
        "\n",
        "#모형 만들기\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import TensorBoard\n",
        "LOG_DIR = 'log_model'\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "model.fit_generator(\n",
        "    train, validation_data=valid,steps_per_epoch=10, validation_steps=5, epochs=5,\n",
        "    callbacks=[\n",
        "        TensorBoard(log_dir=LOG_DIR),\n",
        "        ModelCheckpoint('cnn-{epoch:02d}.hdf5', save_best_only=True),\n",
        "    ])\n",
        "\n",
        "from keras.preprocessing.image import load_img \n",
        "img = load_img('dog-vs-cat/validation/cat/cat.1000.jpg', target_size=(100, 100))\n",
        "import numpy\n",
        "img_array = numpy.array(img) / 255\n",
        "img_array.shape\n",
        "model.predict(numpy.array([img_array]))\n",
        "\n",
        "\n",
        "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "#!unzip -o ngrok-stable-linux-amd64.zip\n",
        "#get_ipython().system_raw(f'tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 6006 &')\n",
        "#get_ipython().system_raw('./ngrok http 6006 &')\n",
        "#! curl -s http://localhost:4040/api/tunnels | tr '\"' '\\n' | grep \"https://\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_17 (Conv2D)           (None, 96, 96, 32)        2432      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_17 (MaxPooling (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 46, 46, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_18 (MaxPooling (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_9 (Flatten)          (None, 16928)             0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 16928)             0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 16929     \n",
            "=================================================================\n",
            "Total params: 28,609\n",
            "Trainable params: 28,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 9s 859ms/step - loss: 0.7227 - acc: 0.5281 - val_loss: 0.5363 - val_acc: 1.0000\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 6s 610ms/step - loss: 0.7010 - acc: 0.5187 - val_loss: 0.6706 - val_acc: 0.6375\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 6s 629ms/step - loss: 0.7479 - acc: 0.4594 - val_loss: 0.6835 - val_acc: 0.5875\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 6s 627ms/step - loss: 0.6974 - acc: 0.4875 - val_loss: 0.6434 - val_acc: 0.8938\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 6s 619ms/step - loss: 0.6932 - acc: 0.5531 - val_loss: 0.6564 - val_acc: 0.8187\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4958537]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    }
  ]
}