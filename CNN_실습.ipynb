{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_실습.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jubeam/my_js_project/blob/master/CNN_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqPacsBowt7A",
        "colab_type": "code",
        "outputId": "d6ff5ed8-4f85-4b4f-b9bc-03ef2f9f7c6b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 863
        }
      },
      "source": [
        "from urllib.request import urlretrieve\n",
        "urlretrieve('http://doc.mindscale.kr/km/unstructured/dog-vs-cat.zip',\n",
        "            'dog-vs-cat.zip')\n",
        "from zipfile import ZipFile\n",
        "\n",
        "with ZipFile('dog-vs-cat.zip') as z:\n",
        "    z.extractall()\n",
        "\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "img_gen = ImageDataGenerator(\n",
        "        rescale=1/255,         # 픽셀 값을 0~1 범위로 변환\n",
        "        rotation_range=40,      # 40도까지 회전\n",
        "        width_shift_range=0.2,  # 20%까지 좌우 이동\n",
        "        height_shift_range=0.2, # 20%까지 상하 이동\n",
        "        shear_range=0.2,        # 20%까지 기울임\n",
        "        zoom_range=0.2,         # 20%까지 확대\n",
        "        horizontal_flip=True,   # 좌우 뒤집기\n",
        "    )\n",
        "\n",
        "train = img_gen.flow_from_directory(\n",
        "    'dog-vs-cat/train',     # 이미지 디렉토리\n",
        "    target_size=(100, 100), # 변환할 크기는 가로 100, 세로 100\n",
        "    color_mode='rgb',       # 컬러는 rgb, 흑백은 grayscale. 생략하면 컬러로 처리한다\n",
        "    class_mode='binary')    # 고양이 vs. 개로 binary 분류\n",
        "\n",
        "valid = ImageDataGenerator(rescale=1/255).flow_from_directory(\n",
        "    'dog-vs-cat/validation',\n",
        "    target_size=(100, 100),\n",
        "    class_mode='binary',\n",
        "    shuffle=False)\n",
        "\n",
        "#모형 만들기\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(100, 100, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "from keras.optimizers import Adam, RMSprop\n",
        "from keras.callbacks import TensorBoard\n",
        "LOG_DIR = 'log_model'\n",
        "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=Adam())\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "model.fit_generator(\n",
        "    train, validation_data=valid,steps_per_epoch=10, validation_steps=5, epochs=5,\n",
        "    callbacks=[\n",
        "        TensorBoard(log_dir=LOG_DIR),\n",
        "        ModelCheckpoint('cnn-{epoch:02d}.hdf5', save_best_only=True),\n",
        "    ])\n",
        "\n",
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip -o ngrok-stable-linux-amd64.zip\n",
        "get_ipython().system_raw(f'tensorboard --logdir {LOG_DIR} --host 0.0.0.0 --port 6006 &')\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "! curl -s http://localhost:4040/api/tunnels | tr '\"' '\\n' | grep \"https://\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2000 images belonging to 2 classes.\n",
            "Found 800 images belonging to 2 classes.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 96, 96, 32)        2432      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 48, 48, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 46, 46, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_5 (Flatten)          (None, 16928)             0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 16928)             0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 16929     \n",
            "=================================================================\n",
            "Total params: 28,609\n",
            "Trainable params: 28,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - 8s 842ms/step - loss: 0.7258 - acc: 0.4656 - val_loss: 1.0750 - val_acc: 0.0063\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - 6s 612ms/step - loss: 0.7388 - acc: 0.4781 - val_loss: 0.9868 - val_acc: 0.0000e+00\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - 6s 627ms/step - loss: 0.7012 - acc: 0.5250 - val_loss: 0.6912 - val_acc: 0.5250\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - 6s 605ms/step - loss: 0.6935 - acc: 0.5219 - val_loss: 0.7044 - val_acc: 0.3563\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - 6s 621ms/step - loss: 0.7051 - acc: 0.5312 - val_loss: 0.9300 - val_acc: 0.0000e+00\n",
            "--2019-07-03 12:26:24--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 3.209.102.29, 52.45.111.123, 54.165.51.142, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|3.209.102.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17556757 (17M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.2’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  16.74M  19.0MB/s    in 0.9s    \n",
            "\n",
            "2019-07-03 12:26:25 (19.0 MB/s) - ‘ngrok-stable-linux-amd64.zip.2’ saved [17556757/17556757]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "  inflating: ngrok                   \n",
            "https://299aba12.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}